{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ebc865b",
   "metadata": {},
   "source": [
    "#### This Sheet contains two models \n",
    "#### Frist Model :  Manually selected  features after multiple interation of VIF & P values calculation\n",
    "#### Second Model: Feature Selected using RFE and then manually tune using VIF & P values calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea9cace",
   "metadata": {},
   "source": [
    "# First Model ( Manual Feature Selection) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ebc558",
   "metadata": {},
   "source": [
    "### Import the required libaray for data frame, data visiualization, model selection, data split for training & testing, Linear Regression, stats modeling, calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fc2915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import calendar\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65d1e64",
   "metadata": {},
   "source": [
    "### Load bike rent  csv file data into the bike_df data frame, check the shape, find the numerical data's stats, also check if there is any missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6783d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df = pd.read_csv('C:/Asheesh/upgrade/bikeRent/day.csv')\n",
    "bike_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b681edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fine the data frame shape\n",
    "bike_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa9ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the describption numerical data\n",
    "bike_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3448bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#find the columns data type and if there is any missing value\n",
    "bike_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39628e3",
   "metadata": {},
   "source": [
    "It is good,  there is no missing value from 16 columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b693c5",
   "metadata": {},
   "source": [
    "### Now find what are the different uniqure values integer columns contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa977c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique values of weekday column\n",
    "bike_df['weekday'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4370900",
   "metadata": {},
   "source": [
    "weekday contains unique values 0 to 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb3a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique values of workingday column\n",
    "bike_df['workingday'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745deee4",
   "metadata": {},
   "source": [
    "Integer column workingday contains unique values 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b19908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique values of holiday column\n",
    "bike_df['holiday'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048d0492",
   "metadata": {},
   "source": [
    "Integer column holiday contains unique values 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6378364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique values of mnth column\n",
    "bike_df['mnth'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b49f63f",
   "metadata": {},
   "source": [
    "Integer column mnth contains unique values 1 and 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7333c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique values of season columns\n",
    "bike_df['season'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4260dd1f",
   "metadata": {},
   "source": [
    "Integer column season contains unique values 1 to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d955b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique values of yr columns\n",
    "bike_df['yr'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf1e74d",
   "metadata": {},
   "source": [
    "Integer column yr contains unique values 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9994a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique values of weathersit columns\n",
    "bike_df['weathersit'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7796c671",
   "metadata": {},
   "source": [
    "Integer column weathersit contains unique values 1 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c8afdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce839bc2",
   "metadata": {},
   "source": [
    "### Finding the pair plot among the non categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c649429",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(bike_df[['cnt','temp','atemp','hum','windspeed','casual','registered']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8af245",
   "metadata": {},
   "source": [
    "From the above pair plot we can see there is strong relation between temp & atemp.cloumns\n",
    "linear relation between cnt and temp, atemp columns\n",
    "linear relation between cnt and casual, registered column columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf445115",
   "metadata": {},
   "source": [
    "### Heat map amoung the non categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9de8b7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(bike_df[['cnt','temp','atemp','hum','windspeed','casual','registered']].corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5b9b6",
   "metadata": {},
   "source": [
    "From the above heatmap  we can see there is strong correlation between cnt, registered and causal columns\n",
    "Good correlation between cnt, temp and atemp\n",
    "strong correlation between temp & atemp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80beda56",
   "metadata": {},
   "source": [
    "### Find out the box plot between cnt and other  categorical variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e2fcf5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "plt.subplot(2,3,1)\n",
    "sns.boxplot(x='holiday',y='cnt', data=bike_df)\n",
    "plt.subplot(2,3,2)\n",
    "sns.boxplot(x='season',y='cnt', data=bike_df)\n",
    "plt.subplot(2,3,3)\n",
    "sns.boxplot(x='mnth',y='cnt', data=bike_df)\n",
    "plt.subplot(2,3,4)\n",
    "sns.boxplot(x='weathersit',y='cnt', data=bike_df)\n",
    "plt.subplot(2,3,5)\n",
    "sns.boxplot(x='weekday',y='cnt', data=bike_df)\n",
    "plt.subplot(2,3,6)\n",
    "sns.boxplot(x='workingday',y='cnt', data=bike_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98af107",
   "metadata": {},
   "source": [
    "75 percentile for holiday and non-holiday is same. \n",
    "For season fall we count goes high.\n",
    "Form 5th to 10th month, count goes high.\n",
    "When weather is clear, count goes up and when weather is heavy count goes down. \n",
    "Median of the weekday is almost same while 75 percentile go up during the mid of the week. \n",
    "Median of working and non-working day is same. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21522c0",
   "metadata": {},
   "source": [
    "### Map the categorial variables numerical values with corresponding string values, then create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e46c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bike_df['season'] = bike_df['season'].astype(str)\n",
    "# bike_df['weathersit'] = bike_df['weathersit'].astype(str)\n",
    "bike_df['season'] = bike_df['season'].map({1: 'spring', 2:'summer', 3:'fall', 4:'winter'})\n",
    "bike_df['weathersit'] = bike_df['weathersit'].map({1: 'clear', 2:'mist', 3:'light', 4:'heavy'})\n",
    "bike_df['mnth'] = bike_df['mnth'].apply(lambda x: calendar.month_abbr[x])\n",
    "bike_df['weekday'] = bike_df['weekday'].apply(lambda x: calendar.day_abbr[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8726db16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b31d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy varialbes for categorical variables and drop their first columns as using n-1 columns we can achive the same things.\n",
    "season = pd.get_dummies(bike_df['season'],dtype='int', drop_first=True)\n",
    "weathersit = pd.get_dummies(bike_df['weathersit'],dtype='int', drop_first=True)\n",
    "month = pd.get_dummies(bike_df['mnth'],dtype='int',drop_first=True)\n",
    "weekday = pd.get_dummies(bike_df['weekday'],dtype='int', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de7efe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop variables for which we have created the dummy variables\n",
    "bike_df = bike_df.drop(['season', 'weathersit', 'mnth', 'weekday'], axis=1)\n",
    "# drop the registered , casual columns as these are directly giving the cnt. \n",
    "# dropping workingday as workingday column contains redundant information as the same info we can achive using holiday and workday columns\n",
    "# dropping instant & dteday as instant & dteday are numerical values but their mean, median, mode and other stats does not help \n",
    "bike_df = bike_df.drop(['registered', 'casual','workingday', 'instant', 'dteday'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd42d518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatnating dummies to bike_df for our modeling\n",
    "bike_df=pd.concat([bike_df,season,weathersit,month,weekday], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5d3728",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking the all variables including dummies\n",
    "bike_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d41410",
   "metadata": {},
   "source": [
    "### Spliting the data, standardize the numerical data, then train the model using OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ebd114",
   "metadata": {},
   "source": [
    "In this approach, first I am dropping variable one by one after checking the VIF and p-values. \n",
    "Doing iteration in following way \n",
    "High VIF & High p value\n",
    "High VIF & Low p value\n",
    "Low VIF & High p value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac68b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data set\n",
    "df_train, df_test = train_test_split(bike_df, test_size=0.3, random_state=100)\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e5d647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the numerical data using min max scaler\n",
    "num_vars=['windspeed', 'cnt','temp', 'atemp', 'hum']\n",
    "scalar= MinMaxScaler()\n",
    "df_train[num_vars]=scalar.fit_transform(df_train[num_vars])\n",
    "df_train[num_vars].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadb1dca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train model using OLS\n",
    "y_train=df_train.pop('cnt')\n",
    "X_train=df_train\n",
    "X_train_sm= sm.add_constant(X_train)\n",
    "lr = sm.OLS(y_train,X_train_sm)\n",
    "lr_model = lr.fit()\n",
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474dafc5",
   "metadata": {},
   "source": [
    "R square is 0.85 which is good, but there is variable which have high pvalue too(not very good case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc5837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the current model using the split test data\n",
    "df_test[num_vars]= scalar.transform(df_test[num_vars])\n",
    "df_test.head()\n",
    "y_test=df_test['cnt']\n",
    "X_test=df_test.drop('cnt',axis=1)\n",
    "X_test_sm= sm.add_constant(X_test)\n",
    "y_test_pred= lr_model.predict(X_test_sm)\n",
    "r2_score(y_true=y_test, y_pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da5c30a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check the variance inflation factor for current columns \n",
    "vif=pd.DataFrame()\n",
    "vif['Features']=X_train.columns\n",
    "vif['VIF']= [variance_inflation_factor(X_train.values,i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by='VIF', ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1baeeef",
   "metadata": {},
   "source": [
    "temp , atemp, hum, spring, winter, summer have high VIF(more than 5), highest p-value among these,  atemp have. So we will drop atemp  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c8a8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop atemp variable and build model again\n",
    "bike_df = bike_df.drop([ 'atemp'], axis=1)\n",
    "df_train, df_test = train_test_split(bike_df, test_size=0.3, random_state=100)\n",
    "y_train=df_train.pop('cnt')\n",
    "X_train=df_train\n",
    "X_train_sm= sm.add_constant(X_train)\n",
    "lr = sm.OLS(y_train,X_train_sm)\n",
    "lr_model = lr.fit()\n",
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a9650",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif=pd.DataFrame()\n",
    "vif['Features']=X_train.columns\n",
    "vif['VIF']= [variance_inflation_factor(X_train.values,i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by='VIF', ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac06278",
   "metadata": {},
   "source": [
    "After removing the atemp, R square is 85. temp, hum, spring, winter, windspeed and summer have high VIF(more than 5), highest VIF temp have So I will drop temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5d7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df = bike_df.drop([ 'temp'], axis=1)\n",
    "df_train, df_test = train_test_split(bike_df, test_size=0.3, random_state=100)\n",
    "y_train=df_train.pop('cnt')\n",
    "X_train=df_train\n",
    "X_train_sm= sm.add_constant(X_train)\n",
    "lr = sm.OLS(y_train,X_train_sm)\n",
    "lr_model = lr.fit()\n",
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3718c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vif=pd.DataFrame()\n",
    "vif['Features']=X_train.columns\n",
    "vif['VIF']= [variance_inflation_factor(X_train.values,i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by='VIF', ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de5f40b",
   "metadata": {},
   "source": [
    "After removing the temp, R square is 82.  hum, spring, winter have high VIF(more than 5), highest VIF hum have So I will drop hum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815542f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df = bike_df.drop([ 'hum'], axis=1)\n",
    "df_train, df_test = train_test_split(bike_df, test_size=0.3, random_state=100)\n",
    "y_train=df_train.pop('cnt')\n",
    "X_train=df_train\n",
    "X_train_sm= sm.add_constant(X_train)\n",
    "lr = sm.OLS(y_train,X_train_sm)\n",
    "lr_model = lr.fit()\n",
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c36bfb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vif=pd.DataFrame()\n",
    "vif['Features']=X_train.columns\n",
    "vif['VIF']= [variance_inflation_factor(X_train.values,i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by='VIF', ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abba523",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df = bike_df.drop([ 'winter'], axis=1)\n",
    "df_train, df_test = train_test_split(bike_df, test_size=0.3, random_state=100)\n",
    "y_train=df_train.pop('cnt')\n",
    "X_train=df_train\n",
    "X_train_sm= sm.add_constant(X_train)\n",
    "lr = sm.OLS(y_train,X_train_sm)\n",
    "lr_model = lr.fit()\n",
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536cd241",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif=pd.DataFrame()\n",
    "vif['Features']=X_train.columns\n",
    "vif['VIF']= [variance_inflation_factor(X_train.values,i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by='VIF', ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca70f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df = bike_df.drop(['spring'], axis=1)\n",
    "df_train, df_test = train_test_split(bike_df, test_size=0.3, random_state=100)\n",
    "y_train=df_train.pop('cnt')\n",
    "X_train=df_train\n",
    "X_train_sm= sm.add_constant(X_train)\n",
    "lr = sm.OLS(y_train,X_train_sm)\n",
    "lr_model = lr.fit()\n",
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534a5206",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vif=pd.DataFrame()\n",
    "vif['Features']=X_train.columns\n",
    "vif['VIF']= [variance_inflation_factor(X_train.values,i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by='VIF', ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be5ec4f",
   "metadata": {},
   "source": [
    "After removing the hum, spring, winter, R square is 81.  now VIF of windspeed is more than 05 high VIF. So I will drop windspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3bb16c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bike_df = bike_df.drop([ 'windspeed'], axis=1)\n",
    "df_train, df_test = train_test_split(bike_df, test_size=0.3, random_state=100)\n",
    "y_train=df_train.pop('cnt')\n",
    "X_train=df_train\n",
    "X_train_sm= sm.add_constant(X_train)\n",
    "lr = sm.OLS(y_train,X_train_sm)\n",
    "lr_model = lr.fit()\n",
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4139562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif=pd.DataFrame()\n",
    "vif['Features']=X_train.columns\n",
    "vif['VIF']= [variance_inflation_factor(X_train.values,i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by='VIF', ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352f226c",
   "metadata": {},
   "source": [
    "After removing high VIF, VIFs are in control. There are some varaibles which have high p-values. So need to remove those varaibles too. Removing the days (other than Mon & Fri days) as these days have high p values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d7a70a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bike_df = bike_df.drop([ 'Tue','Wed', 'Thu', 'Sat', 'Sun'], axis=1)\n",
    "df_train, df_test = train_test_split(bike_df, test_size=0.3, random_state=100)\n",
    "y_train=df_train.pop('cnt')\n",
    "X_train=df_train\n",
    "X_train_sm= sm.add_constant(X_train)\n",
    "lr = sm.OLS(y_train,X_train_sm)\n",
    "lr_model = lr.fit()\n",
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26781ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vif=pd.DataFrame()\n",
    "vif['Features']=X_train.columns\n",
    "vif['VIF']= [variance_inflation_factor(X_train.values,i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by='VIF', ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02f5e0e",
   "metadata": {},
   "source": [
    "Now removing the nov month as it have high p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fec7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df = bike_df.drop([ 'Nov'], axis=1)\n",
    "df_train, df_test = train_test_split(bike_df, test_size=0.3, random_state=100)\n",
    "y_train=df_train.pop('cnt')\n",
    "X_train=df_train\n",
    "X_train_sm= sm.add_constant(X_train)\n",
    "lr = sm.OLS(y_train,X_train_sm)\n",
    "lr_model = lr.fit()\n",
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2130d9db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vif=pd.DataFrame()\n",
    "vif['Features']=X_train.columns\n",
    "vif['VIF']= [variance_inflation_factor(X_train.values,i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by='VIF', ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12403ff",
   "metadata": {},
   "source": [
    "#### After multiple iteration of remvoing variable and VIF, Now current model's R square is 0.791 and all the variable have very low p value and VIF doing the residual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d75f62c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# draw the displot of the Residual  \n",
    "y_pred=lr_model.predict(X_train_sm)\n",
    "res=y_train-y_pred\n",
    "sns.displot(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc46fe47",
   "metadata": {},
   "source": [
    "Residual is creating a normalized distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab1ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=df_test['cnt']\n",
    "X_test=df_test.drop('cnt',axis=1)\n",
    "X_test_sm= sm.add_constant(X_test)\n",
    "y_test_pred= lr_model.predict(X_test_sm)\n",
    "r2_score(y_true=y_test, y_pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9764fd9",
   "metadata": {},
   "source": [
    "#### For the this mdoe on the test data set, the R square is 0.76 which looks pretty fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e1e70a",
   "metadata": {},
   "source": [
    "# Second Model( Feature Selection using RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ded0ced",
   "metadata": {},
   "source": [
    "### Now creating the model using the automated feature selection RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe9c9d4",
   "metadata": {},
   "source": [
    "In this approach, first I am suing the RFE for selection feature and then doing some manual tunining after checking VIF and p values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6e871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leading the data in bike_df_ref data frame \n",
    "bike_df_ref = pd.read_csv('C:/Asheesh/upgrade/bikeRent/day.csv')\n",
    "bike_df_ref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping category variable then creating the dummy variable, \n",
    "# dropping 'season', 'weathersit', 'mnth', 'weekday'\n",
    "# dropping 'registered', 'casual','workingday', 'instant', 'dteday'\n",
    "# concatnating dummy varibles to the bike_df_ref datafrom \n",
    "bike_df_ref['season'] = bike_df_ref['season'].map({1: 'spring', 2:'summer', 3:'fall', 4:'winter'})\n",
    "bike_df_ref['weathersit'] = bike_df_ref['weathersit'].map({1: 'clear', 2:'mist', 3:'light', 4:'heavy'})\n",
    "bike_df_ref['mnth'] = bike_df_ref['mnth'].apply(lambda x: calendar.month_abbr[x])\n",
    "bike_df_ref['weekday'] = bike_df_ref['weekday'].apply(lambda x: calendar.day_abbr[x])\n",
    "season = pd.get_dummies(bike_df_ref['season'],dtype='int', drop_first=True)\n",
    "weathersit = pd.get_dummies(bike_df_ref['weathersit'],dtype='int', drop_first=True)\n",
    "month = pd.get_dummies(bike_df_ref['mnth'],dtype='int',drop_first=True)\n",
    "weekday = pd.get_dummies(bike_df_ref['weekday'],dtype='int', drop_first=True)\n",
    "bike_df_ref = bike_df_ref.drop(['season', 'weathersit', 'mnth', 'weekday'], axis=1)\n",
    "bike_df_ref = bike_df_ref.drop(['registered', 'casual','workingday', 'instant', 'dteday'], axis=1)\n",
    "bike_df_ref=pd.concat([bike_df_ref,season,weathersit,month,weekday], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53319562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the the data frame for training and testing, and then standardizing the data. \n",
    "df_train, df_test = train_test_split(bike_df_ref, test_size=0.3, random_state=100)\n",
    "num_vars=['windspeed', 'cnt','temp', 'atemp', 'hum']\n",
    "scalar= MinMaxScaler()\n",
    "df_train[num_vars]=scalar.fit_transform(df_train[num_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3422a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the features using FFE\n",
    "y_train=df_train.pop('cnt')\n",
    "X_train=df_train\n",
    "lm= LinearRegression()\n",
    "ref= RFE(lm, step=25)\n",
    "ref.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaaa53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the columns and their ranking on the bases of RFE\n",
    "list(zip(X_train.columns, ref.support_, ref.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce0e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "col= X_train.columns[ref.support_]\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d52780",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[~ref.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186adffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using given reference variables\n",
    "X_train_ref=df_train[col]\n",
    "X_train_ref= sm.add_constant(X_train_ref)\n",
    "lr = sm.OLS(y_train,X_train_ref)\n",
    "lr_model = lr.fit()\n",
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec4070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the VIF\n",
    "vif=pd.DataFrame()\n",
    "vif['Features']=X_train.columns\n",
    "vif['VIF']= [variance_inflation_factor(X_train.values,i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by='VIF', ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b9e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the current model \n",
    "df_test[num_vars]= scalar.transform(df_test[num_vars])\n",
    "df_test.head()\n",
    "y_test=df_test['cnt']\n",
    "X_test=df_test[col]\n",
    "X_test_sm= sm.add_constant(X_test)\n",
    "y_test_pred= lr_model.predict(X_test_sm)\n",
    "r2_score(y_true=y_test, y_pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f405e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop temp as it has high VIF\n",
    "col=col.drop('temp')\n",
    "X_train_ref=df_train[col]\n",
    "X_train_ref= sm.add_constant(X_train_ref)\n",
    "lr = sm.OLS(y_train,X_train_ref)\n",
    "lr_model = lr.fit()\n",
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again VIF of the remaining columns\n",
    "vif=pd.DataFrame()\n",
    "X_train =X_train[col]\n",
    "vif['Features']=X_train.columns\n",
    "vif['VIF']= [variance_inflation_factor(X_train.values,i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by='VIF', ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3842ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop hum column and train model again\n",
    "col=col.drop('hum')\n",
    "X_train_ref=df_train[col]\n",
    "X_train_ref= sm.add_constant(X_train_ref)\n",
    "lr = sm.OLS(y_train,X_train_ref)\n",
    "lr_model = lr.fit()\n",
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91de78a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chedk VIF\n",
    "vif=pd.DataFrame()\n",
    "X_train =X_train[col]\n",
    "vif['Features']=X_train.columns\n",
    "vif['VIF']= [variance_inflation_factor(X_train.values,i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by='VIF', ascending=False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c4927",
   "metadata": {},
   "source": [
    "#### Model have 0.83 R square which is good.  P value of the columns are zero or very less. This is my final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107424dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resudial analysis\n",
    "y_test=df_test['cnt']\n",
    "X_test=df_test[col]\n",
    "X_test_sm= sm.add_constant(X_test)\n",
    "y_test_pred= lr_model.predict(X_test_sm)\n",
    "r2_score(y_true=y_test, y_pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dd839f",
   "metadata": {},
   "source": [
    "#### For this Model, Test data R square is 0.80 which is good. Residual analysis of this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70875c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the displot of the Residual\n",
    "y_pred=lr_model.predict(X_train_ref)\n",
    "res=y_train-y_pred\n",
    "sns.displot(res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ef6d59",
   "metadata": {},
   "source": [
    "#### Residual is creating a normalized distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b2c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
